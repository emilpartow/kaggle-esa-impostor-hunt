import os
import time
import pandas as pd
from tqdm import tqdm
import json
import re
import yaml
import requests


def extract_first_json(text):
    """
    Return the first JSON-looking substring from `text` (from '{' to '}'),
    using a non-greedy regex. If nothing matches, return the original text.

    Notes
    -----
    - This is a best-effort helper for models that sometimes prepend/append
      extra text around a JSON object.
    """
    matches = re.findall(r'\{.*?\}', text, re.DOTALL)
    if matches:
        return matches[0]
    return text  # Fallback: hand back the raw string


def safe_json_loads(s):
    """
    Attempt to parse JSON from string `s`. If it fails, try to fix a common
    issue where closing curly braces are missing by balancing '{' and '}'.

    Returns
    -------
    dict | list | None
        Parsed JSON on success, otherwise None.
    """
    try:
        return json.loads(s)
    except Exception:
        s_fixed = s.strip()
        open_count = s_fixed.count("{")
        close_count = s_fixed.count("}")
        if open_count > close_count:
            s_fixed += "}" * (open_count - close_count)
            try:
                return json.loads(s_fixed)
            except Exception:
                pass
        return None


def query_grok_gpt(document_a, document_b, api_key, max_retries=5, wait=4, timeout=120):
    """
    Call xAI's Grok Chat Completions API to decide which of two texts is FAKE.

    The function sends a strict prompt requesting a single-line JSON object:
        {"fake": "A"|"B", "scores": {"A": float, "B": float}}

    It retries transient failures up to `max_retries` times with `wait` seconds
    between attempts. The response is post-processed to extract the first JSON-
    looking substring and to tolerate missing closing braces.

    Parameters
    ----------
    document_a : str
        Text for candidate A.
    document_b : str
        Text for candidate B.
    api_key : str
        xAI API key (Bearer token).
    max_retries : int, optional
        Maximum attempts for the HTTP call.
    wait : int | float, optional
        Seconds to sleep between retries.
    timeout : int | float, optional
        Requests timeout in seconds.

    Returns
    -------
    dict
        {"fake": "A"/"B"/None, "scores": {"A": float|None, "B": float|None}}
    """
    # Robust, unambiguous prompt
    system_content = (
        "You are an impartial fake document detection assistant. "
        "You analyze English scientific and organizational texts from the European Space Agency (ESA). "
        "These documents are about space missions, scientific devices, research results, workshops, and profiles of people such as scientists and astronauts. "
        "Your job is to help identify hallucinated or fake outputs from LLM-modified documents."
    )
    user_content = (
        "You are given two English texts, labeled A and B. "
        "Both are modified versions of original ESA documents, generated by large language models (LLMs). "
        "Exactly one text is 'real' (most similar to the original), the other is 'fake' (contains more errors or hallucinations). "
        "The order of A and B is random. Each text has been heavily changed by LLMs.\n\n"
        "Your task: Decide which text is FAKE.\n\n"
        "**STRICT OUTPUT INSTRUCTIONS:**\n"
        "Your output must be a single-line, valid JSON object, starting with '{' and ending with '}', with this structure:\n"
        '{\"fake\": \"A\" or \"B\", \"scores\": {\"A\": float, \"B\": float}}\n'
        "No explanations, comments, markdown, or extra words. Output ONLY valid JSON, parsable with json.loads().\n"
        "If uncertain, make your best guess.\n"
        "**It is crucial that your response includes both the opening and closing curly braces ({{ ... }})! Do NOT omit the closing curly brace.**\n\n"
        "Example (strict!):\n"
        '{\"fake\": \"A\", \"scores\": {\"A\": 0.87, \"B\": 0.13}}\n\n'
        f"Document A:\n{document_a}\n\n"
        f"Document B:\n{document_b}\n"
    )
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "messages": [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content},
        ],
        "model": "grok-4-latest",
        "stream": False,
        "temperature": 0,
    }
    url = "https://api.x.ai/v1/chat/completions"

    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=timeout)
            response.raise_for_status()
            content = response.json()["choices"][0]["message"]["content"]

            # Try to strip to the first JSON object and parse it safely
            content = extract_first_json(content)
            output = safe_json_loads(content)
            if not isinstance(output, dict):
                raise ValueError("No JSON object found")

            fake = output.get("fake")
            scores = output.get("scores", {})

            if fake not in ["A", "B"]:
                print(f"Original response:\n{content}")
                raise ValueError(f"Invalid 'fake' value: {fake}")

            score_a = safe_float(scores.get("A"), api_response=output, context="grok_a_score")
            score_b = safe_float(scores.get("B"), api_response=output, context="grok_b_score")
            if (score_a is None) or (score_b is None):
                print(f"Original response:\n{content}")
                raise ValueError(f"Invalid score(s): {scores}")

            return {"fake": fake, "scores": {"A": score_a, "B": score_b}}

        except Exception as e:
            print(f"Grok API error (try {attempt + 1}/{max_retries}): {e}")
            if 'content' in locals():
                print(f"Original response:\n{content}")
            time.sleep(wait)

    return {"fake": None, "scores": {"A": None, "B": None}}


def safe_float(val, api_response=None, context=""):
    """
    Convert `val` to float, printing a helpful debug message on failure.

    Parameters
    ----------
    val : Any
        Value to convert.
    api_response : Any, optional
        Full API response (for debugging).
    context : str, optional
        Label to include in error messages.

    Returns
    -------
    float | None
        Float on success, otherwise None.
    """
    try:
        return float(val)
    except Exception as e:
        print(f"[safe_float] Failed to convert '{val}' (context '{context}'). Exception: {e}")
        if api_response is not None:
            print(f"Full API response:\n{api_response}")
        return None


def add_second_and_third_grok(df, api_key, out_csv, sleep_per_call=3, save_every=1):
    """
    Augment a DataFrame with two additional Grok predictions and a final decision.

    Workflow per row
    ----------------
    1) If the first prediction (`grok_fake`, `grok_a_score`, `grok_b_score`) is missing,
       call the API to fill it.
    2) If the second prediction (`grok_fake_2`, ...) is missing, call the API to fill it.
    3) If pred1 == pred2 and both are valid ("A" or "B"): set `grok_decision` to that value.
       Otherwise, compute a third prediction (`grok_fake_3`, ...) and set `grok_decision`
       to the third prediction if valid.
    4) Periodically save the DataFrame to `out_csv` (resume-friendly).

    Resume Behavior
    ---------------
    - If `out_csv` exists, it is loaded and any already processed rows/columns are merged
      back into `df` (based on `id` when available) so the process can resume.

    Parameters
    ----------
    df : pandas.DataFrame
        Must contain 'text_A' and 'text_B'. If available, also 'grok_fake',
        'grok_a_score', 'grok_b_score' to avoid recomputation.
    api_key : str
        xAI API key for Grok.
    out_csv : str
        Path to the CSV file to write progress/results to.
    sleep_per_call : int | float, optional
        Seconds to sleep between API calls (rate limiting / politeness).
    save_every : int, optional
        Save after this many processed rows.

    Returns
    -------
    None
        (Side effect: writes `out_csv` repeatedly and at the end.)
    """
    # Ensure output columns exist
    for col in [
        "grok_fake_2", "grok_a_score_2", "grok_b_score_2",
        "grok_fake_3", "grok_a_score_3", "grok_b_score_3",
        "grok_decision"
    ]:
        if col not in df.columns:
            df[col] = None

    # Resume mode: if an output file exists, load it and merge known results
    if os.path.exists(out_csv):
        print(f"Loading existing file {out_csv} (resume mode)")
        df_out = pd.read_csv(out_csv)

        if "id" in df.columns and "id" in df_out.columns:
            df = df.set_index("id")
            df_out = df_out.set_index("id")

            for col in [
                "grok_fake_2", "grok_a_score_2", "grok_b_score_2",
                "grok_fake_3", "grok_a_score_3", "grok_b_score_3",
                "grok_decision"
            ]:
                if col not in df_out.columns:
                    df_out[col] = None

            for col in [
                "grok_fake_2", "grok_a_score_2", "grok_b_score_2",
                "grok_fake_3", "grok_a_score_3", "grok_b_score_3",
                "grok_decision"
            ]:
                df[col] = df_out[col]

            df = df.reset_index()
        else:
            for col in [
                "grok_fake_2", "grok_a_score_2", "grok_b_score_2",
                "grok_fake_3", "grok_a_score_3", "grok_b_score_3",
                "grok_decision"
            ]:
                if col in df_out.columns:
                    df[col] = df_out[col]

    need_idx = df[df["grok_decision"].isnull()].index
    print(f"{len(need_idx)} rows left to process (resume mode enabled)")

    for count, idx in enumerate(tqdm(need_idx, desc=f"Processing {out_csv}")):
        row = df.loc[idx]
        try:
            # 1) First prediction (if missing)
            pred1 = row.get("grok_fake")
            score_a_1 = row.get("grok_a_score")
            score_b_1 = row.get("grok_b_score")

            if pd.isnull(pred1):
                res1 = query_grok_gpt(row['text_A'], row['text_B'], api_key)
                pred1 = res1.get("fake")
                scores1 = res1.get("scores", {})
                score_a_1 = safe_float(scores1.get("A"), api_response=res1, context="grok_a_score_1")
                score_b_1 = safe_float(scores1.get("B"), api_response=res1, context="grok_b_score_1")

                # Always keep decision if fake is "A" or "B"
                if pred1 in ["A", "B"]:
                    df.at[idx, "grok_fake"] = pred1
                    df.at[idx, "grok_a_score"] = score_a_1
                    df.at[idx, "grok_b_score"] = score_b_1
                else:
                    print(f"Invalid API response for first prediction at row {idx}: {res1}")
                    df.at[idx, "grok_fake"] = None
                    df.at[idx, "grok_a_score"] = None
                    df.at[idx, "grok_b_score"] = None
                    pred1 = None

            # 2) Second prediction (if missing)
            pred2 = row.get("grok_fake_2")
            if pd.isnull(pred2):
                time.sleep(sleep_per_call)
                res2 = query_grok_gpt(row['text_A'], row['text_B'], api_key)
                pred2 = res2.get("fake")
                scores2 = res2.get("scores", {})
                score_a_2 = safe_float(scores2.get("A"), api_response=res2, context="grok_a_score_2")
                score_b_2 = safe_float(scores2.get("B"), api_response=res2, context="grok_b_score_2")

                if pred2 in ["A", "B"]:
                    df.at[idx, "grok_fake_2"] = pred2
                    df.at[idx, "grok_a_score_2"] = score_a_2
                    df.at[idx, "grok_b_score_2"] = score_b_2
                else:
                    print(f"Invalid API response for second prediction at row {idx}: {res2}")
                    df.at[idx, "grok_fake_2"] = None
                    df.at[idx, "grok_a_score_2"] = None
                    df.at[idx, "grok_b_score_2"] = None
                    pred2 = None
            else:
                score_a_2 = row.get("grok_a_score_2")
                score_b_2 = row.get("grok_b_score_2")

            # 3) Final decision logic
            if pred1 == pred2 and pred1 in ["A", "B"]:
                df.at[idx, "grok_decision"] = pred2
            else:
                # 3rd prediction (tie-breaker)
                pred3 = row.get("grok_fake_3")
                if pd.isnull(pred3):
                    time.sleep(sleep_per_call)
                    res3 = query_grok_gpt(row['text_A'], row['text_B'], api_key)
                    pred3 = res3.get("fake")
                    scores3 = res3.get("scores", {})
                    score_a_3 = safe_float(scores3.get("A"), api_response=res3, context="grok_a_score_3")
                    score_b_3 = safe_float(scores3.get("B"), api_response=res3, context="grok_b_score_3")

                    if pred3 in ["A", "B"]:
                        df.at[idx, "grok_fake_3"] = pred3
                        df.at[idx, "grok_a_score_3"] = score_a_3
                        df.at[idx, "grok_b_score_3"] = score_b_3
                        df.at[idx, "grok_decision"] = pred3
                    else:
                        print(f"Invalid API response for third prediction at row {idx}: {res3}")
                        df.at[idx, "grok_fake_3"] = None
                        df.at[idx, "grok_a_score_3"] = None
                        df.at[idx, "grok_b_score_3"] = None
                        df.at[idx, "grok_decision"] = None
                else:
                    pred3 = row.get("grok_fake_3")
                    if pred3 in ["A", "B"]:
                        df.at[idx, "grok_decision"] = pred3
                    else:
                        df.at[idx, "grok_decision"] = None

        except Exception as e:
            print(f"Error in row {idx}: {e}")
            for col in [
                "grok_fake_2", "grok_a_score_2", "grok_b_score_2",
                "grok_fake_3", "grok_a_score_3", "grok_b_score_3",
                "grok_decision"
            ]:
                df.at[idx, col] = None

        # Persist progress frequently (resume-friendly)
        if ((count + 1) % save_every == 0) or (idx == need_idx[-1]):
            df.to_csv(out_csv, index=False)

        time.sleep(sleep_per_call)

    print(f"Finished writing: {out_csv}")


if __name__ == "__main__":
    # Usage:
    # 1) Read configuration (API key),
    # 2) Load train/test DataFrames,
    # 3) Run the augmentation function,
    # 4) Save back to the same CSVs (resume-friendly).

    try:
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    except NameError:
        root_dir = os.path.abspath("..")

    data_dir = os.path.join(root_dir, "data")
    src_dir = os.path.join(root_dir, "src")
    train_path = os.path.join(data_dir, "train.csv")
    test_path = os.path.join(data_dir, "test.csv")
    config_path = os.path.join(src_dir, "config.yaml")

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)
    api_key = config["xai_api_key"]

    train_df = pd.read_csv(train_path)
    add_second_and_third_grok(train_df, api_key, train_path, sleep_per_call=1)

    test_df = pd.read_csv(test_path)
    add_second_and_third_grok(test_df, api_key, test_path, sleep_per_call=3)